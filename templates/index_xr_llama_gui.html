<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Camera Interaction App</title>
    <style>
        body {
            font-family: sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 20px;
            padding: 20px;
            background-color: #e20a0a;
        }

        .controls,
        .io-areas {
            display: flex;
            gap: 10px;
            align-items: center;
            background-color: #111ed8;
            padding: 15px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }

        .io-areas {
            flex-direction: column;
            align-items: stretch;
        }

        textarea {
            width: 300px;
            height: 80px;
            padding: 8px;
            border: 1px solid #000000;
            border-radius: 4px;
            font-size: 14px;
        }

        #videoFeed {
            width: 480px;
            height: 360px;
            border: 2px solid #d0d30e;
            background-color: #3be719;
            border-radius: 8px;
        }

        #startButton {
            padding: 10px 20px;
            font-size: 16px;
            cursor: pointer;
            border: none;
            border-radius: 4px;
            color: rgb(247, 243, 243);
        }

        #startButton.start {
            background-color: #28a745;
            /* Green */
        }

        #startButton.stop {
            background-color: #dc3545;
            /* Red */
        }

        label {
            font-weight: bold;
        }

        select {
            padding: 8px;
            border-radius: 4px;
            border: 2px solid #d40303;
        }

        .hidden {
            display: none;
        }

        @media (max-width: 768px) {
            #container {
                flex-direction: column;
                height: auto;
            }

            #ui-container,
            #threejs-container {
                width: 100% !important;
            }

            #videoFeed {
                width: 100% !important;
                height: auto !important;
            }

            textarea {
                width: 100% !important;
            }

            #threejs-container canvas {
                width: 100% !important;
                height: auto !important;
            }
        }
    </style>
    <script type="importmap">
    {
      "imports": {
        "three": "https://unpkg.com/three@0.172.0/build/three.module.js",
        "three/addons/": "https://unpkg.com/three@0.172.0/examples/jsm/"
      }
    }
  </script>

</head>

<body>

    <h1>VLM and Three.js</h1>
    <div id="container" style="display: flex; width: 100%; height: 80vh; gap: 20px;">
        <video id="videoFeed" autoplay playsinline style="width: 100%; height: auto; border-radius: 8px;"
            capture="environment"></video>
        <canvas id="canvas" class="hidden"></canvas> <!-- For capturing frames -->
        <script type="module">
            //----------------------------------------------------------------------------
            // Three.js
            //----------------------------------------------------------------------------
            import * as THREE from "three";
            import { OrbitControls } from 'three/addons/controls/OrbitControls.js';
            import { VRButton } from 'three/addons/webxr/VRButton.js';//vr
            import { XRButton } from 'three/addons/webxr/XRButton.js';//vr
            import { XRControllerModelFactory } from 'three/addons/webxr/XRControllerModelFactory.js';//mr
            import { MTLLoader } from 'https://unpkg.com/three@0.172.0/examples/jsm/loaders/MTLLoader.js';
            import { OBJLoader } from 'https://unpkg.com/three@0.172.0/examples/jsm/loaders/OBJLoader.js';
            import { CSS2DRenderer, CSS2DObject } from 'three/addons/renderers/CSS2DRenderer.js';
            import { FontLoader } from 'three/addons/loaders/FontLoader.js';
            import { TextGeometry } from 'three/addons/geometries/TextGeometry.js';

            import { GUI } from 'three/addons/libs/lil-gui.module.min.js';
            import { HTMLMesh } from 'three/addons/interactive/HTMLMesh.js';//3D gui
            import { InteractiveGroup } from 'three/addons/interactive/InteractiveGroup.js';//3D gui


            let chatTextMesh = null;
            let screenTextMesh = null;
            let responseText = "I am thinking...";
            let debugText = "start"
            let stream;
            let isProcessing = false;

            // Scene setup
            const scene = new THREE.Scene();
            const renderer = new THREE.WebGLRenderer();
            renderer.setSize(window.innerWidth, window.innerHeight);
            document.body.appendChild(renderer.domElement);

            // Set white background using renderer
            renderer.setClearColor(0xffffff, 1);  // 0xffffff = white, 1 = fully opaque


            renderer.xr.enabled = true;//vr
            // document.body.appendChild(VRButton.createButton(renderer));//vr
            document.body.appendChild(XRButton.createButton(renderer, {
                'optionalFeatures': ['depth-sensing'],
                'depthSensing': { 'usagePreference': ['gpu-optimized'], 'dataFormatPreference': [] }
            }));//mr
            // document.body.appendChild(XRButton.createButton(renderer));//mr


            // // show image
            // var geometry = new THREE.BoxGeometry(0, 2, 1);
            // const textureLoader = new THREE.TextureLoader();
            // const texture = textureLoader.load("https://upload.wikimedia.org/wikipedia/commons/thumb/b/bb/Gorille_des_plaines_de_l%27ouest_%C3%A0_l%27Espace_Zoologique.jpg/440px-Gorille_des_plaines_de_l%27ouest_%C3%A0_l%27Espace_Zoologique.jpg");
            // const material = new THREE.MeshBasicMaterial({ map: texture });
            // var image = new THREE.Mesh(geometry, material);
            // image.position.set(0, 1, 1);
            // scene.add(image);


            // Camera
            const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            camera.position.set(0, 0.16, 0.5);
            camera.lookAt(0, 0.16, 0);

            // Controls
            const OBcontrol = new OrbitControls(camera, renderer.domElement);

            // Add a stronger ambient light
            const ambientLight = new THREE.AmbientLight(0xffffff, 0.8);
            scene.add(ambientLight);

            // Add a directional light with shadows
            const directionalLight = new THREE.DirectionalLight(0xffffff, 1.0);
            directionalLight.position.set(5, 10, 7.5);
            scene.add(directionalLight);

            // World
            const world = new THREE.Group();  // Master group for scaling
            scene.add(world);

            // Screen
            const geometry = new THREE.BoxGeometry(6, 3, 0.1);
            const material = new THREE.MeshStandardMaterial({ color: 0x5555ff });
            const monitor = new THREE.Mesh(geometry, material);
            monitor.position.set(0, 3, 0);
            world.add(monitor);

            // Chat box
            const chatBox_g = new THREE.BoxGeometry(3, 1, 0.1);
            const chatBox_m = new THREE.MeshStandardMaterial({ color: 0x00ff00 });
            const chatBox = new THREE.Mesh(chatBox_g, chatBox_m);
            chatBox.position.set(0, 1, 1);
            world.add(chatBox);

            // AI teacher
            const mtlLoader = new MTLLoader();
            mtlLoader.setPath('/static/CatModel/');
            mtlLoader.load('cat.mtl', (materials) => {
                materials.preload();
                const objLoader = new OBJLoader();
                objLoader.setMaterials(materials);
                objLoader.setPath('/static/CatModel/');
                objLoader.load('cat.obj', (object) => {
                    object.position.set(2, 0, 0);
                    object.scale.set(0.05, 0.05, 0.05);
                    object.rotation.x = -Math.PI / 2;
                    world.add(object);
                    console.log("Cat model added");
                });
            });

            // Cross Markers
            function mark_closs(x, y, z) {
                const material = new THREE.LineBasicMaterial({ color: 0x808080 });
                const points = [new THREE.Vector3(-0.5, 0, 0), new THREE.Vector3(0.5, 0, 0)];
                const geometry = new THREE.BufferGeometry().setFromPoints(points);
                const line_x = new THREE.Line(geometry, material);
                const line_y = new THREE.Line(geometry, material);
                line_x.position.set(x, y, z);
                line_y.position.set(x, y, z);
                line_y.rotation.y = Math.PI / 2;
                world.add(line_x);
                world.add(line_y);
            }
            function set_cross() {
                const y = 0;
                for (let x = -5; x < 5; x += 1) {
                    for (let z = -5; z < 5; z += 1) {
                        mark_closs(x, y, z);
                    }
                }
            }
            // set_cross();

            //----------------------------------------------------------------------------
            // Get video stream from workstation
            //----------------------------------------------------------------------------
            const ws = new WebSocket("wss://161.3.140.22:8443");
            ws.onopen = () => ws.send(JSON.stringify({ role: "receiver" }));

            const pc = new RTCPeerConnection();
            const video = document.getElementById("videoFeed");

            pc.ontrack = (event) => {
                video.srcObject = event.streams[0];
            };

            pc.onicecandidate = e => {
                if (e.candidate) {
                    ws.send(JSON.stringify({ role: "receiver", candidate: e.candidate }));
                }
            };

            ws.onmessage = async (event) => {
                const data = JSON.parse(event.data);
                if (data.type === "offer") {
                    await pc.setRemoteDescription({ type: "offer", sdp: data.sdp });
                    const answer = await pc.createAnswer();
                    await pc.setLocalDescription(answer);
                    ws.send(JSON.stringify({ role: "receiver", type: "answer", sdp: answer.sdp }));
                } else if (data.candidate) {
                    pc.addIceCandidate(new RTCIceCandidate(data.candidate));
                }
            };

            //----------------------------------------------------------------------------
            // Communicate with actual camera and VLM
            //----------------------------------------------------------------------------
            // const video = document.getElementById('videoFeed');
            const canvas = document.getElementById('canvas');
            const baseURL = "http://127.0.0.1:8080"; // address of VLM server but it will be converted to https
            const instructionText = "Explain this equation"; // default instruction


            // Returns response text (string)
            async function sendChatCompletionRequest(instruction, imageBase64URL) {
                const response = await fetch(`${baseURL}/v1/chat/completions`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        max_tokens: 100,
                        messages: [
                            {
                                role: 'user', content: [
                                    { type: 'text', text: instruction },
                                    {
                                        type: 'image_url', image_url: {
                                            url: imageBase64URL,
                                        }
                                    }
                                ]
                            },
                        ]
                    })
                });
                if (!response.ok) {
                    const errorData = await response.text();
                    return `Server error: ${response.status} - ${errorData}`;
                }
                const data = await response.json();
                return data.choices[0].message.content;
            }

            // 1. Ask for camera permission on load
            async function initCamera() {
                try {
                    stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
                    video.srcObject = stream;
                    responseText = "Camera access granted. Ready to start.";
                    console.log(responseText);
                } catch (err) {
                    console.error("Error accessing camera:", err);
                    responseText = `Error accessing camera: ${err.name} - ${err.message}. Please ensure permissions are granted and you are on HTTPS or localhost.`;
                    console.log(responseText);
                    alert(`Error accessing camera: ${err.name}. Make sure you've granted permission and are on HTTPS or localhost.`);
                }
            }

            function captureImage() {// It does not work!!!!

                if (!stream || !video.videoWidth) {
                    console.warn("Video stream not ready for capture.");
                    responseText = "Video stream not ready for capture.";
                    return null;
                }
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                const context = canvas.getContext('2d');
                context.drawImage(video, 0, 0, canvas.width, canvas.height);
                return canvas.toDataURL('image/jpeg', 0.8); // Use JPEG for smaller size, 0.8 quality
            }

            async function sendData(imageBase64URL) {
                if (!isProcessing) return; // Ensure we don't have overlapping requests if processing takes longer than interval

                const instruction = instructionText;

                if (!imageBase64URL) {
                    responseText = "Failed to capture image. Stream might not be active.";
                    console.log(responseText);
                    // Optionally stop processing if image capture fails consistently
                    // handleStop();
                    return;
                }

                const payload = {
                    instruction: instruction,
                    imageBase64URL: imageBase64URL
                };

                try {
                    const response = await sendChatCompletionRequest(payload.instruction, payload.imageBase64URL);
                    responseText = response;
                    console.log(responseText);
                } catch (error) {
                    console.error('Error sending data:', error);
                    // responseText = `Error: ${error.message}`;
                }
            }

            // Handle Capture on Button Click
            function handleCapture() {
                isProcessing = true;
                const imageBase64URL = captureImage();
                debugText = "captured"
                sendData(imageBase64URL);
                stopCamera(); // Stop the camera stream after capturing the image
            }

            // Stop the camera stream
            function stopCamera() {
                if (stream) {
                    stream.getTracks().forEach(track => track.stop());  // Stop all tracks (video/audio)
                    video.srcObject = null; // Disconnect the video stream
                    console.log("Camera stream stopped.");
                }
            }

            // Initialize camera when the page loads
            window.addEventListener('DOMContentLoaded', initCamera);


            //---------------------------------------------------------------------------------------------
            // Text grometry



            function disp_text(chat_text, screen_text) {
                const loader = new FontLoader();
                loader.load('https://threejs.org/examples/fonts/helvetiker_regular.typeface.json', function (font) {
                    const textMaterial = new THREE.MeshStandardMaterial({ color: 0x000000 });

                    // Remove old text meshes if they exist
                    if (chatTextMesh) world.remove(chatTextMesh);
                    if (screenTextMesh) world.remove(screenTextMesh);

                    // Chat text
                    const chatTextGeometry = new TextGeometry(chat_text, {
                        font: font,
                        size: 0.2,
                        depth: 0.05
                    });
                    chatTextMesh = new THREE.Mesh(chatTextGeometry, textMaterial);
                    chatTextMesh.position.set(-1.3, 1, 1.1);
                    world.add(chatTextMesh);

                    // Screen text
                    const screenTextGeometry = new TextGeometry(screen_text, {
                        font: font,
                        size: 0.2,
                        depth: 0.05
                    });
                    screenTextMesh = new THREE.Mesh(screenTextGeometry, textMaterial);
                    screenTextMesh.position.set(-2.5, 4, 0.1);
                    world.add(screenTextMesh);
                });
            }
            setInterval(() => {
                const newText = new Date().toLocaleTimeString();
                disp_text(debugText, responseText);
            }, 1000); // update every 5 seconds

            // responseText = await sendChatCompletionRequest(...);
            // disp_text("AI:", responseText);





            // Scale world to fit MR view
            world.scale.set(0.1, 0.1, 0.1); // Shrink to 10%
            world.position.set(0, 0.9, -0.7);

            //-----------------------------------------------------

            // Stop rendering
            let isBButtonPressed = false;
            function stopRendering() {
                isBButtonPressed = true;
            }

            //-------------------------------------------------------

            // Create the dat.GUI interface
            const gui = new GUI();
            gui.add({ capture: handleCapture }, 'capture').name('Capture Image'); // Add button for capture
            gui.add({ stop_rendering: stopRendering }, 'stop_rendering').name('Stop rendering'); // Add button for stop rendering

            // vr controller
            const controller_g = new THREE.BufferGeometry();
            controller_g.setFromPoints([new THREE.Vector3(0, 0, 0), new THREE.Vector3(0, 0, - 5)]);
            const controller1 = renderer.xr.getController(0);
            controller1.add(new THREE.Line(controller_g));
            scene.add(controller1);
            const controller2 = renderer.xr.getController(1);
            controller2.add(new THREE.Line(controller_g));
            scene.add(controller2);
            const controllerModelFactory = new XRControllerModelFactory();
            const controllerGrip1 = renderer.xr.getControllerGrip(0);
            controllerGrip1.add(controllerModelFactory.createControllerModel(controllerGrip1));
            scene.add(controllerGrip1);
            const controllerGrip2 = renderer.xr.getControllerGrip(1);
            controllerGrip2.add(controllerModelFactory.createControllerModel(controllerGrip2));
            scene.add(controllerGrip2);

            // 3D GUI
            gui.domElement.style.visibility = 'hidden';
            const group = new InteractiveGroup();
            group.listenToPointerEvents(renderer, camera);
            group.listenToXRControllerEvents(controller1);
            group.listenToXRControllerEvents(controller2);
            scene.add(group);
            const mesh = new HTMLMesh(gui.domElement);
            mesh.position.set(0, 0.85, -0.5);
            mesh.scale.set(0.05, 0.05, 0.05);
            // mesh.rotation.y = Math.PI / 5;
            mesh.scale.setScalar(2);
            group.add(mesh);

            

            //----------------------------------------------------------------------------------
            // let isBButtonPressed = false;
            // controller1.addEventListener('connected', (event) => {
            //     if (event.data.handedness == "left") {
            //         //do something here
            //     }
            //     if (event.data.handedness == "right") {
            //         controller1.gamepad = event.data.gamepad;
            //         // const bButton = controller1.gamepad.buttons[1]; // B button
            //         if (controller1.gamepad.buttons[1]) {
            //             isBButtonPressed = true;
            //         }
            //     }
            //     //get buttons inputs from controller 1

            // });


            function animate() {
                if (!isBButtonPressed) {

                    requestAnimationFrame(animate);
                    ThreeMeshUI.update();
                    renderer.render(scene, camera);
                }
            }
            if (!isBButtonPressed) {
                renderer.setAnimationLoop(animate); // mr
                animate();
            }
            // </script>
    </div>

</body>

</html>